+++
title = 'Policy gradient'
date = 2024-06-12T01:24:48+09:00
draft = false
description = ''
tags = ['Reinforcement Learning']
+++
<!-- 
{{< showimg >}}
cover.jpg
{{< /showimg >}} -->

<!-- この更新を繰り返せば方策πのもとでの真の価値関数vπ(s)に収束することが証明されている。 -->
{{< br >}}{{< /br >}}
https://rail.eecs.berkeley.edu/deeprlcourse-fa18/static/slides/lec-5.pdf
{{< br >}}{{< /br >}}{{< br >}}{{< /br >}}{{< br >}}{{< /br >}}
{{< mathjax >}}
$$ E=mc^2 $$
$$ \frac{1}{2} \cdot (x + y) $$
$$ f(x) = x^2 $$
$$ x = 2 $$
$$\displaystyle \int_{-\infty }^{\infty}f(x)dx$$
$$ \lim_{n \to \infty} \frac{1}{n} = 0 $$
$$  V^*(s) = \max_a \left[ R(s, a) + \gamma \sum_{s'} P(s' | s, a) V^*(s') \right]  $$

$$\begin{align}
&a=x+y+z\
&b+c=w
\end{align}$$

$$\begin{flalign}
&a=x+y+z\
&b+c=w
\end{flalign}$$

{{< /mathjax >}}